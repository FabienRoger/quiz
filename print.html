<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Deep Learning Quiz</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="intro.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="module2.html"><strong aria-hidden="true">2.</strong> Module 2</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="02_basics_runall.html"><strong aria-hidden="true">2.1.</strong> notebook + quiz</a></li><li class="chapter-item expanded "><a href="02_basics_quiz.html"><strong aria-hidden="true">2.2.</strong> quizzes only</a></li></ol></li><li class="chapter-item expanded "><a href="module3.html"><strong aria-hidden="true">3.</strong> Module 3</a></li><li class="chapter-item expanded "><a href="tbc.html"><strong aria-hidden="true">4.</strong> TBC</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Deep Learning Quiz</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <p><a href="https://dataflowr.github.io/website/"><img src="https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png" alt="Dataflowr" /></a></p>
<p>This website contains quizzes for the <a href="https://dataflowr.github.io/website/">Deep Learning course</a>. Modules on the left correspond to modules on this website.</p>
<p>You can uses quizzes to check your understanding of a module. Please follow theses rules:</p>
<p>1 - <strong>Take a quiz as soon as you get to it.</strong></p>
<p>2- <strong>Do not skip a quiz.</strong></p>
<p>Every quiz looks like the one below. Try it out by clicking &quot;Start&quot;.</p>
<div class="quiz-placeholder" data-quiz-name="quiz_0"  data-quiz-questions="{&quot;questions&quot;:[{&quot;context&quot;:&quot;Answer is controversial: ![](./intro_files/twitter_conscious.png)\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:3},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;Yes&quot;,&quot;No&quot;,&quot;Maybe&quot;],&quot;prompt&quot;:&quot;Are neural networks slightly conscious?&quot;}}]}"  data-quiz-commit-hash="59bbd8102c9df64c499fead210142af11519b68a
" ></div>
<p>If you get a question incorrect, you will see the correct answer like above.</p>
<p>Now you are ready to start!<script type="text/javascript" src="mdbook-quiz/embed.js"></script></p>
<link rel="stylesheet" type="text/css" href="mdbook-quiz/embed.css"><div style="break-before: page; page-break-before: always;"></div><p><a href="https://dataflowr.github.io/website/"><img src="https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png" alt="Dataflowr" /></a></p>
<h1 id="module-2-pytorch-tensors-and-automatic-differentiation"><a class="header" href="#module-2-pytorch-tensors-and-automatic-differentiation">Module 2: PyTorch tensors and automatic differentiation</a></h1>
<p>You can either do the quizzes corresponding to <a href="https://dataflowr.github.io/website/modules/2a-pytorch-tensors/">Module 2</a> with a static version of the notebook:</p>
<ul>
<li><a href="./02_basics_runall.html">notebook + quiz</a></li>
</ul>
<p>or just do all the quizzes </p>
<ul>
<li><a href="./02_basics_quiz.html">quizzes only</a></li>
</ul>
<p>If you did not make any mistake, you can safely go to the end of <a href="https://dataflowr.github.io/website/modules/2b-automatic-differentiation/">Module 2b</a></p>
<div style="break-before: page; page-break-before: always;"></div><p><a href="https://dataflowr.github.io/website/"><img src="https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png" alt="Dataflowr" /></a></p>
<h1 id="module-2-pytorch-tensors-and-automatic-differentiation-1"><a class="header" href="#module-2-pytorch-tensors-and-automatic-differentiation-1">Module 2: PyTorch tensors and automatic differentiation</a></h1>
<p><a href="https://youtu.be/BmAS8IH7n3c?t=103">Video timestamp</a></p>
<pre><code class="language-python">import matplotlib.pyplot as plt
%matplotlib inline
import torch
import numpy as np
</code></pre>
<pre><code class="language-python">&gt; torch.__version__
</code></pre>
<pre><code>'1.12.1+cu113'
</code></pre>
<p>Tensors are used to encode the signal to process, but also the internal states and parameters of models.</p>
<p><strong>Manipulating data through this constrained structure allows to use CPUs and GPUs at peak performance.</strong></p>
<p>Construct a 3x5 matrix, uninitialized:</p>
<pre><code class="language-python">x = torch.empty(3,5)
print(x.dtype)
print(x)
</code></pre>
<pre><code>torch.float32
tensor([[7.9394e-35, 0.0000e+00, 3.3631e-44, 0.0000e+00,        nan],
        [0.0000e+00, 1.1578e+27, 1.1362e+30, 7.1547e+22, 4.5828e+30],
        [1.2121e+04, 7.1846e+22, 9.2198e-39, 7.0374e+22, 0.0000e+00]])
</code></pre>
<p>If you got an error this <a href="https://stackoverflow.com/questions/50617917/overflow-when-unpacking-long-pytorch">stackoverflow link</a> might be useful...</p>
<pre><code class="language-python">x = torch.randn(3,5)
print(x)
</code></pre>
<pre><code>tensor([[-0.0515,  0.6647,  0.5428,  2.5307,  0.9185],
        [-0.2556,  0.5543,  1.6044,  0.8425, -1.0667],
        [-0.5247,  0.2197,  0.8738,  0.8047,  0.7197]])
</code></pre>
<pre><code class="language-python">print(x.size())
</code></pre>
<pre><code>torch.Size([3, 5])
</code></pre>
<p>torch.Size is in fact a <a href="https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences">tuple</a>, so it supports the same operations.</p>
<p><a href="https://youtu.be/BmAS8IH7n3c?t=272">Video timestamp</a></p>
<pre><code class="language-python">x.size()[1]
</code></pre>
<pre><code>5
</code></pre>
<pre><code class="language-python">x.size() == (3,5)
</code></pre>
<pre><code>True
</code></pre>
<h3 id="bridge-to-numpy"><a class="header" href="#bridge-to-numpy">Bridge to numpy</a></h3>
<p><a href="https://youtu.be/BmAS8IH7n3c?t=325">Video timestamp</a></p>
<pre><code class="language-python">y = x.numpy()
print(y)
</code></pre>
<pre><code>[[-0.05147836  0.6646777   0.54277486  2.5307057   0.9185137 ]
 [-0.25555766  0.55434686  1.6044122   0.8425406  -1.0667061 ]
 [-0.52467006  0.21967238  0.87380797  0.8046722   0.7197009 ]]
</code></pre>
<pre><code class="language-python">a = np.ones(5)
b = torch.from_numpy(a)
print(a.dtype)
print(b)
</code></pre>
<pre><code>float64
tensor([1., 1., 1., 1., 1.], dtype=torch.float64)
</code></pre>
<pre><code class="language-python">c = b.long()
print(c.dtype, c)
print(b.dtype, b)
</code></pre>
<pre><code>torch.int64 tensor([1, 1, 1, 1, 1])
torch.float64 tensor([1., 1., 1., 1., 1.], dtype=torch.float64)
</code></pre>
<pre><code class="language-python">xr = torch.randn(3, 5)
print(xr.dtype, xr)
</code></pre>
<pre><code>torch.float32 tensor([[ 0.4959, -0.8126, -0.7801,  0.9866,  0.5365],
        [-0.9082,  0.1658, -1.2888, -2.4009,  0.5765],
        [-0.4390, -0.6147, -1.3412, -0.0609, -1.0023]])
</code></pre>
<pre><code class="language-python">resb = xr + b
resb
</code></pre>
<pre><code>tensor([[ 1.4959,  0.1874,  0.2199,  1.9866,  1.5365],
        [ 0.0918,  1.1658, -0.2888, -1.4009,  1.5765],
        [ 0.5610,  0.3853, -0.3412,  0.9391, -0.0023]], dtype=torch.float64)
</code></pre>
<pre><code class="language-python">resc = xr + c
resc
</code></pre>
<pre><code>tensor([[ 1.4959,  0.1874,  0.2199,  1.9866,  1.5365],
        [ 0.0918,  1.1658, -0.2888, -1.4009,  1.5765],
        [ 0.5610,  0.3853, -0.3412,  0.9391, -0.0023]])
</code></pre>
<p>Be careful with types!</p>
<pre><code class="language-python">resb == resc
</code></pre>
<pre><code>tensor([[False,  True,  True, False,  True],
        [ True, False,  True,  True, False],
        [False,  True,  True, False,  True]])
</code></pre>
<pre><code class="language-python">torch.set_printoptions(precision=10)
</code></pre>
<pre><code class="language-python">resb[0,1]
</code></pre>
<pre><code>tensor(0.1874370575, dtype=torch.float64)
</code></pre>
<pre><code class="language-python">resc[0,1]
</code></pre>
<pre><code>tensor(0.1874370575)
</code></pre>
<pre><code class="language-python">resc[0,1].dtype
</code></pre>
<pre><code>torch.float32
</code></pre>
<pre><code class="language-python">xr[0,1]
</code></pre>
<pre><code>tensor(-0.8125629425)
</code></pre>
<pre><code class="language-python">torch.set_printoptions(precision=4)
</code></pre>
<h3 id="broadcasting"><a class="header" href="#broadcasting"><a href="https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html">Broadcasting</a></a></h3>
<p><a href="https://youtu.be/BmAS8IH7n3c?t=670">Video timestamp</a></p>
<p>Broadcasting automagically expands dimensions by replicating coefficients, when it is necessary to perform operations.</p>
<ol>
<li>If one of the tensors has fewer dimensions than the other, it is reshaped by adding as many dimensions of size 1 as necessary in the front; then</li>
<li>for every mismatch, if one of the two tensor is of size one, it is expanded along this axis by replicating  coefficients.</li>
</ol>
<p>If there is a tensor size mismatch for one of the dimension and neither of them is one, the operation fails.</p>
<pre><code class="language-python">A = torch.tensor([[1.], [2.], [3.], [4.]])
print(A.size())
B = torch.tensor([[5., -5., 5., -5., 5.]])
print(B.size())
C = A + B
</code></pre>
<pre><code>torch.Size([4, 1])
torch.Size([1, 5])
</code></pre>
<pre><code class="language-python">C
</code></pre>
<pre><code>tensor([[ 6., -4.,  6., -4.,  6.],
        [ 7., -3.,  7., -3.,  7.],
        [ 8., -2.,  8., -2.,  8.],
        [ 9., -1.,  9., -1.,  9.]])
</code></pre>
<h3 id="in-place-modification"><a class="header" href="#in-place-modification">In-place modification</a></h3>
<p><a href="https://youtu.be/BmAS8IH7n3c?t=875">Video timestamp</a></p>
<pre><code class="language-python">x
</code></pre>
<pre><code>tensor([[-0.0515,  0.6647,  0.5428,  2.5307,  0.9185],
        [-0.2556,  0.5543,  1.6044,  0.8425, -1.0667],
        [-0.5247,  0.2197,  0.8738,  0.8047,  0.7197]])
</code></pre>
<pre><code class="language-python">xr
</code></pre>
<pre><code>tensor([[ 0.4959, -0.8126, -0.7801,  0.9866,  0.5365],
        [-0.9082,  0.1658, -1.2888, -2.4009,  0.5765],
        [-0.4390, -0.6147, -1.3412, -0.0609, -1.0023]])
</code></pre>
<pre><code class="language-python">print(x+xr)
</code></pre>
<pre><code>tensor([[ 0.4444, -0.1479, -0.2373,  3.5173,  1.4550],
        [-1.1637,  0.7201,  0.3156, -1.5584, -0.4903],
        [-0.9636, -0.3950, -0.4674,  0.7438, -0.2826]])
</code></pre>
<pre><code class="language-python">x.add_(xr)
print(x)
</code></pre>
<pre><code>tensor([[ 0.4444, -0.1479, -0.2373,  3.5173,  1.4550],
        [-1.1637,  0.7201,  0.3156, -1.5584, -0.4903],
        [-0.9636, -0.3950, -0.4674,  0.7438, -0.2826]])
</code></pre>
<p>Any operation that mutates a tensor in-place is post-fixed with an <code>_</code></p>
<p>For example: <code>x.fill_(y)</code>, <code>x.t_()</code>, will change <code>x</code>.</p>
<pre><code class="language-python">print(x.t())
</code></pre>
<pre><code>tensor([[ 0.4444, -1.1637, -0.9636],
        [-0.1479,  0.7201, -0.3950],
        [-0.2373,  0.3156, -0.4674],
        [ 3.5173, -1.5584,  0.7438],
        [ 1.4550, -0.4903, -0.2826]])
</code></pre>
<pre><code class="language-python">x.t_()
print(x)
</code></pre>
<pre><code>tensor([[ 0.4444, -1.1637, -0.9636],
        [-0.1479,  0.7201, -0.3950],
        [-0.2373,  0.3156, -0.4674],
        [ 3.5173, -1.5584,  0.7438],
        [ 1.4550, -0.4903, -0.2826]])
</code></pre>
<h3 id="shared-memory"><a class="header" href="#shared-memory">Shared memory</a></h3>
<p><a href="https://youtu.be/BmAS8IH7n3c?t=990">Video timestamp</a></p>
<p>Also be careful, changing the torch tensor modify the numpy array and vice-versa...</p>
<p>This is explained in the PyTorch documentation <a href="https://pytorch.org/docs/stable/torch.html#torch.from_numpy">here</a>:
The returned tensor by <code>torch.from_numpy</code> and ndarray share the same memory. Modifications to the tensor will be reflected in the ndarray and vice versa. </p>
<pre><code class="language-python">a = np.ones(5)
b = torch.from_numpy(a)
print(b)
</code></pre>
<pre><code>tensor([1., 1., 1., 1., 1.], dtype=torch.float64)
</code></pre>
<pre><code class="language-python">a[2] = 0
print(b)
</code></pre>
<pre><code>tensor([1., 1., 0., 1., 1.], dtype=torch.float64)
</code></pre>
<pre><code class="language-python">b[3] = 5
print(a)
</code></pre>
<pre><code>[1. 1. 0. 5. 1.]
</code></pre>
<div class="quiz-placeholder" data-quiz-name="quiz_21"  data-quiz-questions="{&quot;questions&quot;:[{&quot;context&quot;:&quot;`from_numpy()` automatically inherits input array `dtype`.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`float8`&quot;,&quot;`float32`&quot;,&quot;`float64`&quot;],&quot;prompt&quot;:&quot;We run the following code: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ a = np.ones(5) \n$ b = trorch.from_numpy(a) \n$ print(b) \n tensor([1., 1., 1., 1., 1.], dtype=torch.float64)  &lt;/code&gt;&lt;/pre&gt;\n What is the output of `a.dtype`?&quot;}},{&quot;context&quot;:&quot;Because of casting, memory between `a` and `b` is not shared. \n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`[1. 1. 0. 1. 1.]`&quot;,&quot;`[1. 0. 5. 1. 1.]`&quot;,&quot;`[1. 1. 1. 5. 1.]`&quot;,&quot;`[1. 1. 0. 5. 1.]`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ b = b.to(torch.uint8) \n$ a[2] = 0 \n$ b[3] = 5 &lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b)`?&quot;}}]}"  data-quiz-commit-hash="59bbd8102c9df64c499fead210142af11519b68a
" ></div>
<h3 id="cuda"><a class="header" href="#cuda">Cuda</a></h3>
<p><a href="https://youtu.be/BmAS8IH7n3c?t=1120">Video timestamp</a></p>
<pre><code class="language-python">torch.cuda.is_available()
</code></pre>
<pre><code>True
</code></pre>
<pre><code class="language-python">#device = torch.device('cpu')
device = torch.device('cuda') # Uncomment this to run on GPU
</code></pre>
<pre><code class="language-python">x.device
</code></pre>
<pre><code>device(type='cpu')
</code></pre>
<pre><code class="language-python"># let us run this cell only if CUDA is available
# We will use ``torch.device`` objects to move tensors in and out of GPU
if torch.cuda.is_available():
    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU
    x = x.to(device)                       # or just use strings ``.to(&quot;cuda&quot;)``
    z = x + y
    print(z,z.type())
    print(z.to(&quot;cpu&quot;, torch.double))       # ``.to`` can also change dtype together!
</code></pre>
<pre><code>tensor([[ 1.4444, -0.1637,  0.0364],
        [ 0.8521,  1.7201,  0.6050],
        [ 0.7627,  1.3156,  0.5326],
        [ 4.5173, -0.5584,  1.7438],
        [ 2.4550,  0.5097,  0.7174]], device='cuda:0') torch.cuda.FloatTensor
tensor([[ 1.4444, -0.1637,  0.0364],
        [ 0.8521,  1.7201,  0.6050],
        [ 0.7627,  1.3156,  0.5326],
        [ 4.5173, -0.5584,  1.7438],
        [ 2.4550,  0.5097,  0.7174]], dtype=torch.float64)
</code></pre>
<pre><code class="language-python">x = torch.randn(1)
x = x.to(device)
</code></pre>
<pre><code class="language-python">x.device
</code></pre>
<pre><code>device(type='cuda', index=0)
</code></pre>
<pre><code class="language-python"># the following line is only useful if CUDA is available
x = x.data
print(x)
print(x.item())
print(x.cpu().numpy())
</code></pre>
<pre><code>tensor([-0.8821], device='cuda:0')
-0.8821402192115784
[-0.8821402]
</code></pre>
<div class="quiz-placeholder" data-quiz-name="quiz_22"  data-quiz-questions="{&quot;questions&quot;:[{&quot;context&quot;:&quot;`b.to(device)` is not changing `b` in place. \n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:0},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`cpu`&quot;,&quot;`cuda:0`&quot;],&quot;prompt&quot;:&quot;We run the following code: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ a = np.ones(5) \n$ b = torch.from_numpy(a) \n$ torch.cuda.is_available() \nTrue \n$ device = torch.device('cuda') \n$ b.to(device) &lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.device)`&quot;}},{&quot;context&quot;:&quot;`a` is stored on `cpu` and `b`on `gpu`.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`[2., 1., 1., 1., 1.]`&quot;,&quot;`[1., 1., 1., 1., 1.]`&quot;],&quot;prompt&quot;:&quot;We continue with &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ b = b.to(device) \n$ b[0] = 2 \n$ print(b) \n tensor([2., 1., 1., 1., 1.], device='cuda:0', dtype=torch.float64) &lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(a)`?&quot;}}]}"  data-quiz-commit-hash="59bbd8102c9df64c499fead210142af11519b68a
" ></div>
<h1 id="simple-interfaces-to-standard-image-data-bases"><a class="header" href="#simple-interfaces-to-standard-image-data-bases">Simple interfaces to standard image data-bases</a></h1>
<p><a href="https://youtu.be/BmAS8IH7n3c?t=1354">Video timestamp</a></p>
<p>An example, the <a href="https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.CIFAR10">CIFAR10</a> dataset.</p>
<pre><code class="language-python">import torchvision

data_dir = 'content/data'

cifar = torchvision.datasets.CIFAR10(data_dir, train = True, download = True)
cifar.data.shape
</code></pre>
<pre><code>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to content/data/cifar-10-python.tar.gz



  0%|          | 0/170498071 [00:00&lt;?, ?it/s]


Extracting content/data/cifar-10-python.tar.gz to content/data





(50000, 32, 32, 3)
</code></pre>
<p>Documentation about the <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute"><code>permute</code></a> operation.</p>
<pre><code class="language-python">x = torch.from_numpy(cifar.data).permute(0,3,1,2).float()
x = x / 255
print(x.type(), x.size(), x.min().item(), x.max().item())
</code></pre>
<pre><code>torch.FloatTensor torch.Size([50000, 3, 32, 32]) 0.0 1.0
</code></pre>
<p>Documentation about the <a href="https://pytorch.org/docs/stable/torch.html#torch.narrow"><code>narrow(input, dim, start, length)</code></a> operation.</p>
<pre><code class="language-python"># Narrows to the first images, converts to float
x = torch.narrow(x, 0, 0, 48)
</code></pre>
<pre><code class="language-python">x.shape
</code></pre>
<pre><code>torch.Size([48, 3, 32, 32])
</code></pre>
<pre><code class="language-python"># Showing images
def show(img):
    npimg = img.numpy()
    plt.figure(figsize=(20,10))
    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')
    
show(torchvision.utils.make_grid(x, nrow = 12))
</code></pre>
<p><img src="02_basics_runall_files/02_basics_runall_58_0.png" alt="png" /></p>
<pre><code class="language-python"># Kills the green and blue channels
x.narrow(1, 1, 2).fill_(0)
show(torchvision.utils.make_grid(x, nrow = 12))
</code></pre>
<p><img src="02_basics_runall_files/02_basics_runall_59_0.png" alt="png" /></p>
<h1 id="autograd-automatic-differentiation"><a class="header" href="#autograd-automatic-differentiation">Autograd: automatic differentiation</a></h1>
<p><a href="https://youtu.be/Z6H3zakmn6E?t=40">Video timestamp</a></p>
<p>When executing tensor operations, PyTorch can automatically construct on-the-fly the graph of operations to compute the gradient of any quantity with respect to any tensor involved.</p>
<p>To be more concrete, we introduce the following example: we consider parameters $w\in \mathbb{R}$ and $b\in \mathbb{R}$ with the corresponding function:
\begin{eqnarray*}
\ell = \left(\exp(wx+b) - y^* \right)^2
\end{eqnarray*}</p>
<p>Our goal here, will be to compute the following partial derivatives:
\begin{eqnarray*}
\frac{\partial \ell}{\partial w}\mbox{ and, }\frac{\partial \ell}{\partial b}.
\end{eqnarray*}</p>
<p>The reason for doing this will be clear when you will solve the practicals for this lesson!</p>
<p>You can decompose this function as a composition of basic operations. This is call the forward pass on the graph of operations.
<img src="https://dataflowr.github.io/notebooks/Module2/img/backprop1.png" alt="backprop1" /></p>
<p>Let say we start with our model in <code>numpy</code>:</p>
<pre><code class="language-python">w = np.array([0.5])
b = np.array([2])
xx = np.array([0.5])#np.arange(0,1.5,.5)
</code></pre>
<p>transform these into <code>tensor</code>:</p>
<pre><code class="language-python">xx_t = torch.from_numpy(xx)
w_t = torch.from_numpy(w)
b_t = torch.from_numpy(b)
</code></pre>
<p><a href="https://youtu.be/Z6H3zakmn6E?t=224">Video timestamp</a></p>
<p>A <code>tensor</code> has a Boolean field <code>requires_grad</code>, set to <code>False</code> by default, which states if PyTorch should build the graph of operations so that gradients with respect to it can be computed.</p>
<pre><code class="language-python">w_t.requires_grad
</code></pre>
<pre><code>False
</code></pre>
<p>We want to take derivative with respect to $w$ so we change this value:</p>
<pre><code class="language-python">w_t.requires_grad_(True)
</code></pre>
<pre><code>tensor([0.5000], dtype=torch.float64, requires_grad=True)
</code></pre>
<p>We want to do the same thing for $b$ but the following line will produce an error!</p>
<pre><code class="language-python">b_t.requires_grad_(True)
</code></pre>
<pre><code>---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)

&lt;ipython-input-49-68842c726fce&gt; in &lt;module&gt;
----&gt; 1 b_t.requires_grad_(True)


RuntimeError: only Tensors of floating point dtype can require gradients
</code></pre>
<p>Reading the error message should allow you to correct the mistake!</p>
<pre><code class="language-python">dtype = torch.float64
</code></pre>
<pre><code class="language-python">b_t = b_t.type(dtype)
</code></pre>
<pre><code class="language-python">b_t.requires_grad_(True)
</code></pre>
<pre><code>tensor([2.], dtype=torch.float64, requires_grad=True)
</code></pre>
<p><a href="https://youtu.be/Z6H3zakmn6E?t=404">Video timestamp</a></p>
<p>We now compute the function:</p>
<pre><code class="language-python">def fun(x,ystar):
    y = torch.exp(w_t*x+b_t)
    print(y)
    return torch.sum((y-ystar)**2)

ystar_t = torch.randn_like(xx_t)
l_t = fun(xx_t,ystar_t)
</code></pre>
<pre><code>tensor([9.4877], dtype=torch.float64, grad_fn=&lt;ExpBackward0&gt;)
</code></pre>
<pre><code class="language-python">l_t
</code></pre>
<pre><code>tensor(89.3094, dtype=torch.float64, grad_fn=&lt;SumBackward0&gt;)
</code></pre>
<pre><code class="language-python">l_t.requires_grad
</code></pre>
<pre><code>True
</code></pre>
<p>After the computation is finished, i.e. <em>forward pass</em>, you can call <code>.backward()</code> and have all the gradients computed automatically.</p>
<pre><code class="language-python">print(w_t.grad)
</code></pre>
<pre><code>None
</code></pre>
<pre><code class="language-python">l_t.backward()
</code></pre>
<pre><code class="language-python">print(w_t.grad)
print(b_t.grad)
</code></pre>
<pre><code>tensor([89.6626], dtype=torch.float64)
tensor([179.3251], dtype=torch.float64)
</code></pre>
<p><a href="https://youtu.be/Z6H3zakmn6E?t=545">Video timestamp</a></p>
<p>Let's try to understand these numbers...</p>
<p><img src="https://dataflowr.github.io/notebooks/Module2/img/backprop2.png" alt="backprop2" /></p>
<pre><code class="language-python">yy_t = torch.exp(w_t*xx_t+b_t)
print(torch.sum(2*(yy_t-ystar_t)*yy_t*xx_t))
print(torch.sum(2*(yy_t-ystar_t)*yy_t))
</code></pre>
<pre><code>tensor(89.6626, dtype=torch.float64, grad_fn=&lt;SumBackward0&gt;)
tensor(179.3251, dtype=torch.float64, grad_fn=&lt;SumBackward0&gt;)
</code></pre>
<p><code>tensor.backward()</code> accumulates the gradients in  the <code>grad</code> fields  of tensors.</p>
<pre><code class="language-python">l_t = fun(xx_t,ystar_t)
l_t.backward()
</code></pre>
<pre><code>tensor([9.4877], dtype=torch.float64, grad_fn=&lt;ExpBackward0&gt;)
</code></pre>
<pre><code class="language-python">print(w_t.grad)
print(b_t.grad)
</code></pre>
<pre><code>tensor([179.3251], dtype=torch.float64)
tensor([358.6502], dtype=torch.float64)
</code></pre>
<p>By default, <code>backward</code> deletes the computational graph when it is used so that you will get an error below:</p>
<pre><code class="language-python">l_t.backward()
</code></pre>
<pre><code>---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)

&lt;ipython-input-62-e295af15a710&gt; in &lt;module&gt;
----&gt; 1 l_t.backward()


/usr/local/lib/python3.7/dist-packages/torch/_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs)
    394                 create_graph=create_graph,
    395                 inputs=inputs)
--&gt; 396         torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
    397 
    398     def register_hook(self, hook):


/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)
    173     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
    174         tensors, grad_tensors_, retain_graph, create_graph, inputs,
--&gt; 175         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
    176 
    177 def grad(


RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
</code></pre>
<pre><code class="language-python"># Manually zero the gradients
w_t.grad.data.zero_()
b_t.grad.data.zero_()
l_t = fun(xx_t,ystar_t)
l_t.backward(retain_graph=True)
l_t.backward()
print(w_t.grad)
print(b_t.grad)
</code></pre>
<pre><code>tensor([9.4877], dtype=torch.float64, grad_fn=&lt;ExpBackward0&gt;)
tensor([179.3251], dtype=torch.float64)
tensor([358.6502], dtype=torch.float64)
</code></pre>
<p>The gradients must be set to zero manually. Otherwise they will cumulate across several <em>.backward()</em> calls. 
This accumulating behavior is desirable in particular to compute the gradient of a loss summed over several “mini-batches,” or the gradient of a sum of losses.</p>
<div class="quiz-placeholder" data-quiz-name="quiz_23"  data-quiz-questions="{&quot;questions&quot;:[{&quot;context&quot;:&quot;Default value is `False`. \n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`True`&quot;,&quot;`False`&quot;,&quot;`0`&quot;,&quot;`Error`&quot;],&quot;prompt&quot;:&quot;We run the following code: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ b = torch.tensor([1, 1, 1, 5, 1], dtype=torch.float)&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.requires_grad)`?&quot;}},{&quot;context&quot;:&quot;Default value is `None`. \n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`0`&quot;,&quot;`1`&quot;,&quot;`None`&quot;,&quot;`Nan`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ b.requires_grad_(True) \ntensor([1., 1., 1., 5., 1.], requires_grad=True)&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}},{&quot;context&quot;:&quot;The derivative of each component is `2(b_i-1)`.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`tensor([2.])`&quot;,&quot;`tensor([2., 2., 2.,  10.,  2.])`&quot;,&quot;`tensor([0., 0., 0., 8., 0.])`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ l = sum((b-1)**2) \n$ l.backward() \n$ print(l) \ntensor(16., grad_fn=&lt;AddBackward0&gt;)&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}},{&quot;context&quot;:&quot;You cannot compute gradient if you detach the `data` from the `tensor`.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;same as for `l`&quot;,&quot;`Error`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ m = sum((b.data -1)**2) &lt;/code&gt;&lt;/pre&gt;\n What is the output of `m.backward()`?&quot;}},{&quot;context&quot;:&quot;Gradients are added by default.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`tensor([0., 0., 0., 8., 0.])`&quot;,&quot;`tensor([0., 0., 0., 16., 0.])`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ n = sum((b-1)**2) \n$ n.backward() &lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}},{&quot;context&quot;:&quot;There is an error when at `n.backward()`: `RuntimeError: Trying to backward through the graph a second time`\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:0},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`tensor([0., 0., 0., 16., 0.])`&quot;,&quot;`tensor([0., 0., 0., 32., 0.])`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ n.requires_grad_(True) \n$ n.backward()&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}},{&quot;context&quot;:&quot;The tensor `b` is not connected with `m` in the computation graph.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;there is an error at `m.backward()`&quot;,&quot;`tensor([0., 0., 0., 8., 0.])`&quot;,&quot;`tensor([0., 0., 0., 16., 0.])`&quot;,&quot;`tensor([0., 0., 0., 32., 0.])`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ m.requires_grad_(True) \n$ m.backward()&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}}]}"  data-quiz-commit-hash="59bbd8102c9df64c499fead210142af11519b68a
" ></div>
<p><a href="https://dataflowr.github.io/website/"><img src="https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png" alt="Dataflowr" /></a></p>
<pre><code class="language-python">
</code></pre>
<script type="text/javascript" src="mdbook-quiz/embed.js"></script>
<link rel="stylesheet" type="text/css" href="mdbook-quiz/embed.css"><div style="break-before: page; page-break-before: always;"></div><p><a href="https://dataflowr.github.io/website/"><img src="https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png" alt="Dataflowr" /></a></p>
<h1 id="quizzes-only"><a class="header" href="#quizzes-only">quizzes only</a></h1>
<p>All quizzes for <a href="https://dataflowr.github.io/website/modules/2a-pytorch-tensors/">Module 2</a>:</p>
<div class="quiz-placeholder" data-quiz-name="quiz_21"  data-quiz-questions="{&quot;questions&quot;:[{&quot;context&quot;:&quot;`from_numpy()` automatically inherits input array `dtype`.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`float8`&quot;,&quot;`float32`&quot;,&quot;`float64`&quot;],&quot;prompt&quot;:&quot;We run the following code: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ a = np.ones(5) \n$ b = trorch.from_numpy(a) \n$ print(b) \n tensor([1., 1., 1., 1., 1.], dtype=torch.float64)  &lt;/code&gt;&lt;/pre&gt;\n What is the output of `a.dtype`?&quot;}},{&quot;context&quot;:&quot;Because of casting, memory between `a` and `b` is not shared. \n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`[1. 1. 0. 1. 1.]`&quot;,&quot;`[1. 0. 5. 1. 1.]`&quot;,&quot;`[1. 1. 1. 5. 1.]`&quot;,&quot;`[1. 1. 0. 5. 1.]`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ b = b.to(torch.uint8) \n$ a[2] = 0 \n$ b[3] = 5 &lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b)`?&quot;}}]}"  data-quiz-commit-hash="59bbd8102c9df64c499fead210142af11519b68a
" ></div>
<p>If something is unclear, you should probably get a refresher <a href="./02_basics_runall.html#module-2-pytorch-tensors-and-automatic-differentiation">here</a></p>
<div class="quiz-placeholder" data-quiz-name="quiz_22"  data-quiz-questions="{&quot;questions&quot;:[{&quot;context&quot;:&quot;`b.to(device)` is not changing `b` in place. \n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:0},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`cpu`&quot;,&quot;`cuda:0`&quot;],&quot;prompt&quot;:&quot;We run the following code: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ a = np.ones(5) \n$ b = torch.from_numpy(a) \n$ torch.cuda.is_available() \nTrue \n$ device = torch.device('cuda') \n$ b.to(device) &lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.device)`&quot;}},{&quot;context&quot;:&quot;`a` is stored on `cpu` and `b`on `gpu`.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`[2., 1., 1., 1., 1.]`&quot;,&quot;`[1., 1., 1., 1., 1.]`&quot;],&quot;prompt&quot;:&quot;We continue with &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ b = b.to(device) \n$ b[0] = 2 \n$ print(b) \n tensor([2., 1., 1., 1., 1.], device='cuda:0', dtype=torch.float64) &lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(a)`?&quot;}}]}"  data-quiz-commit-hash="59bbd8102c9df64c499fead210142af11519b68a
" ></div>
<p>If something is unclear, you should probably get a refresher <a href="./02_basics_runall.html#cuda">here</a></p>
<div class="quiz-placeholder" data-quiz-name="quiz_23"  data-quiz-questions="{&quot;questions&quot;:[{&quot;context&quot;:&quot;Default value is `False`. \n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`True`&quot;,&quot;`False`&quot;,&quot;`0`&quot;,&quot;`Error`&quot;],&quot;prompt&quot;:&quot;We run the following code: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ b = torch.tensor([1, 1, 1, 5, 1], dtype=torch.float)&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.requires_grad)`?&quot;}},{&quot;context&quot;:&quot;Default value is `None`. \n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`0`&quot;,&quot;`1`&quot;,&quot;`None`&quot;,&quot;`Nan`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ b.requires_grad_(True) \ntensor([1., 1., 1., 5., 1.], requires_grad=True)&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}},{&quot;context&quot;:&quot;The derivative of each component is `2(b_i-1)`.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`tensor([2.])`&quot;,&quot;`tensor([2., 2., 2.,  10.,  2.])`&quot;,&quot;`tensor([0., 0., 0., 8., 0.])`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ l = sum((b-1)**2) \n$ l.backward() \n$ print(l) \ntensor(16., grad_fn=&lt;AddBackward0&gt;)&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}},{&quot;context&quot;:&quot;You cannot compute gradient if you detach the `data` from the `tensor`.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;same as for `l`&quot;,&quot;`Error`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ m = sum((b.data -1)**2) &lt;/code&gt;&lt;/pre&gt;\n What is the output of `m.backward()`?&quot;}},{&quot;context&quot;:&quot;Gradients are added by default.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`tensor([0., 0., 0., 8., 0.])`&quot;,&quot;`tensor([0., 0., 0., 16., 0.])`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ n = sum((b-1)**2) \n$ n.backward() &lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}},{&quot;context&quot;:&quot;There is an error when at `n.backward()`: `RuntimeError: Trying to backward through the graph a second time`\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:0},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`tensor([0., 0., 0., 16., 0.])`&quot;,&quot;`tensor([0., 0., 0., 32., 0.])`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ n.requires_grad_(True) \n$ n.backward()&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}},{&quot;context&quot;:&quot;The tensor `b` is not connected with `m` in the computation graph.\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:2},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;there is an error at `m.backward()`&quot;,&quot;`tensor([0., 0., 0., 8., 0.])`&quot;,&quot;`tensor([0., 0., 0., 16., 0.])`&quot;,&quot;`tensor([0., 0., 0., 32., 0.])`&quot;],&quot;prompt&quot;:&quot;We continue with: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; $ m.requires_grad_(True) \n$ m.backward()&lt;/code&gt;&lt;/pre&gt;\n What is the output of `print(b.grad)`?&quot;}}]}"  data-quiz-commit-hash="59bbd8102c9df64c499fead210142af11519b68a
" ></div>
<p>If something is unclear, you should probably get a refresher <a href="./02_basics_runall.html#autograd-automatic-differentiation">here</a><script type="text/javascript" src="mdbook-quiz/embed.js"></script></p>
<link rel="stylesheet" type="text/css" href="mdbook-quiz/embed.css"><div style="break-before: page; page-break-before: always;"></div><p><a href="https://dataflowr.github.io/website/"><img src="https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png" alt="Dataflowr" /></a></p>
<h1 id="module-3-loss-functions-for-classification"><a class="header" href="#module-3-loss-functions-for-classification">Module 3: Loss functions for classification</a></h1>
<p>These are the quizzes corresponding to <a href="https://dataflowr.github.io/website/modules/3-loss-functions-for-classification/">Module 3</a></p>
<p>In all the questions below we assume that all the import have been done <code>import torch...</code>:</p>
<div class="quiz-placeholder" data-quiz-name="quiz_3"  data-quiz-questions="{&quot;questions&quot;:[{&quot;context&quot;:&quot;tbd \n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;`print(input)`&quot;,&quot;`print(m(input))`&quot;,&quot;`print(output)`&quot;],&quot;prompt&quot;:&quot;We run the following code: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; m = nn.Sigmoid() \nloss = nn.BCELoss() \ntarget = torch.empty(3).random_(2) \nprint(target) \ninput = torch.randn(3, requires_grad=True) \noptimizer = torch.optim.SGD([input], lr = 0.1) \nprint(m(input)) \nfor _ in range(10000): \n    output = loss(m(input), target) \n    optimizer.zero_grad()\n    output.backward()\n    optimizer.step()\nprint(xxxxxx)&lt;/code&gt;&lt;/pre&gt;\n and obtain the following result: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; tensor([0., 0., 1.])\ntensor([0.3517, 0.4834, 0.3328], grad_fn=&lt;SigmoidBackward&gt;)\ntensor([0.0030, 0.0030, 0.9970], grad_fn=&lt;SigmoidBackward&gt;)&lt;/code&gt;&lt;/pre&gt;\n What was the last `print` command ?&quot;}},{&quot;context&quot;:&quot;tbd\n&quot;,&quot;type&quot;:&quot;MultipleChoice&quot;,&quot;answer&quot;:{&quot;answer&quot;:1},&quot;prompt&quot;:{&quot;choices&quot;:[&quot;yes&quot;,&quot;no&quot;],&quot;prompt&quot;:&quot;We run the following code: &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt;target = torch.empty(1,2,3).random_(2) \nprint(target) \ninput = torch.randn((1,2,3), requires_grad=True) \noptimizer = torch.optim.SGD([input], lr = 0.1) \nprint(m(input).size())&lt;/code&gt;&lt;/pre&gt;\n and get &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt; tensor([[[1., 1., 1.],\n         [0., 0., 1.]]])\ntorch.Size([1, 2, 3])&lt;/code&gt;&lt;/pre&gt;\n we then run &lt;pre&gt;&lt;code class=\&quot;language-python\&quot;&gt;for _ in range(10000):\n    output = loss(m(input), target)\n    optimizer.zero_grad()\n    output.backward()\n    optimizer.step()&lt;/code&gt;&lt;/pre&gt;\n Does it produce an error?&quot;}}]}"  data-quiz-commit-hash="59bbd8102c9df64c499fead210142af11519b68a
" ></div>
<p>If you did not make any mistake, you can safely go to <a href="https://dataflowr.github.io/website/modules/4-optimization-for-deep-learning/">Module 4</a><script type="text/javascript" src="mdbook-quiz/embed.js"></script></p>
<link rel="stylesheet" type="text/css" href="mdbook-quiz/embed.css"><div style="break-before: page; page-break-before: always;"></div><p><a href="https://dataflowr.github.io/website/"><img src="https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png" alt="Dataflowr" /></a></p>
<h1 id="tbc"><a class="header" href="#tbc">TBC</a></h1>
<p>You can submit feedback using the <a href="https://github.com/dataflowr/quiz">GitHub repo</a>. Thanks!</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
